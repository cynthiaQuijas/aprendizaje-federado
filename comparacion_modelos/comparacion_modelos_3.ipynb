{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, hagan otro archivo de código para el cómputo del modelo global. Primero usen FedAvg, pero también incluyan otras dos formas de computarlo (investiga, explica brevemente y presenta una implementación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from TheModel import build \n",
    "\n",
    "# cargar los modelos locales entrenados en local_training.ipynb\n",
    "loaded_local_models = [\n",
    "    tf.keras.models.load_model(os.path.join(\".\", file))\n",
    "    for file in sorted(os.listdir(\".\")) if file.startswith(\"lmodel\") and file.endswith(\".keras\")\n",
    "]\n",
    "#  conjunto de entrenamient\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train / 255.0, -1)\n",
    "x_test = np.expand_dims(x_test / 255.0, -1)# normalización y expansion de dimension\n",
    "\n",
    "# obtener los pesos de cada modelo \n",
    "local_weights = [m.get_weights() for m in loaded_local_models]\n",
    "local_sizes = [12000] * len(loaded_local_models)  \n",
    "\n",
    "# conjunto de prueba de MNIST\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_test = np.expand_dims(x_test / 255.0, -1)  # normalización y expansion de dimension\n",
    "\n",
    "# seleccionar un modelo base para la arquitectura\n",
    "base_model = loaded_local_models[0]\n",
    "\n",
    "# función para evaluar un modelo con pesos \n",
    "def evaluate_model(weights, base_model, x_test, y_test):\n",
    "    model = tf.keras.models.clone_model(base_model)  # clona la arquitectura \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.set_weights(weights)  # asigna los pesos agregados\n",
    "\n",
    "    #  predicciones y métricas\n",
    "    y_pred = model.predict(x_test, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    acc = accuracy_score(y_test, y_pred_classes)\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEDAVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servidor central agrega los modelos recibidos de los clientes promediando sus parámetros. Este proceso de promediación garantiza que el modelo global aproveche la información obtenida de los diferentes clientes, preservando al mismo tiempo la privacidad. Es simple, eficiente y funciona bien cuando los datos están balanceados\n",
    "\n",
    "https://how.dev/answers/what-is-federated-averaging-fedavg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32       980\n",
      "           1       0.38      0.99      0.55      1135\n",
      "           2       0.95      0.04      0.07      1032\n",
      "           3       0.59      0.24      0.35      1010\n",
      "           4       1.00      0.00      0.00       982\n",
      "           5       0.73      0.45      0.56       892\n",
      "           6       1.00      0.01      0.03       958\n",
      "           7       0.50      0.58      0.53      1028\n",
      "           8       0.28      0.81      0.42       974\n",
      "           9       0.39      0.72      0.51      1009\n",
      "\n",
      "    accuracy                           0.41     10000\n",
      "   macro avg       0.68      0.40      0.33     10000\n",
      "weighted avg       0.68      0.41      0.34     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fed_avg(weights):\n",
    "    return [np.mean(np.array(w), axis=0) for w in zip(*weights)]\n",
    "\n",
    "fedavg_weights = fed_avg(local_weights)\n",
    "evaluate_model(fedavg_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FED WEIGHTED AVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una extensión de FedAvg al ponderar cada modelo local según la cantidad de datos que usó para entrenarse. Esto hace que modelos con mayor volumen de datos tengan mayor influencia en el modelo global. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32       980\n",
      "           1       0.38      0.99      0.55      1135\n",
      "           2       0.95      0.04      0.07      1032\n",
      "           3       0.59      0.24      0.35      1010\n",
      "           4       1.00      0.00      0.00       982\n",
      "           5       0.73      0.45      0.56       892\n",
      "           6       1.00      0.01      0.03       958\n",
      "           7       0.50      0.58      0.53      1028\n",
      "           8       0.28      0.81      0.42       974\n",
      "           9       0.39      0.72      0.51      1009\n",
      "\n",
      "    accuracy                           0.41     10000\n",
      "   macro avg       0.68      0.40      0.33     10000\n",
      "weighted avg       0.68      0.41      0.34     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fed_weighted_avg(weights, sizes):\n",
    "    total = sum(sizes)\n",
    "    return [\n",
    "        np.sum([w * (s / total) for w, s in zip(layer, sizes)], axis=0)\n",
    "        for layer in zip(*weights)\n",
    "    ]\n",
    "fedweighted_weights = fed_weighted_avg(local_weights, local_sizes)\n",
    "evaluate_model(fedweighted_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FED MEDIAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula la mediana de los pesos de cada capa entre todos los modelos. Su ventaja es la tolerancia a valores extremos pero puede afectar la precisión considerablemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.14      0.25       980\n",
      "           1       0.53      0.97      0.68      1135\n",
      "           2       0.63      0.02      0.04      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       1.00      0.00      0.01       982\n",
      "           5       0.55      0.46      0.50       892\n",
      "           6       1.00      0.00      0.01       958\n",
      "           7       0.60      0.11      0.18      1028\n",
      "           8       0.14      0.78      0.24       974\n",
      "           9       0.36      0.55      0.43      1009\n",
      "\n",
      "    accuracy                           0.31     10000\n",
      "   macro avg       0.57      0.30      0.23     10000\n",
      "weighted avg       0.57      0.31      0.24     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fed_median(weights):\n",
    "    return [np.median(np.array(w), axis=0) for w in zip(*weights)]\n",
    "\n",
    "fedmedian_weights = fed_median(local_weights)\n",
    "evaluate_model( fedmedian_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FED MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma el valor máximo por posición en cada capa de pesos entre los modelos locales. Es una estrategia experimental y se ha usado para estudiar comportamientos extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.09      1.00      0.16       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.51      0.04      0.07      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.09     10000\n",
      "   macro avg       0.06      0.10      0.02     10000\n",
      "weighted avg       0.06      0.09      0.02     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# FED MAX: Máximo valor por capa (experimental, no recomendable en la práctica)\n",
    "def fed_max(weights):\n",
    "    return [np.max(np.array(w), axis=0) for w in zip(*weights)]\n",
    "\n",
    "# Aplicamos la agregación por máximo\n",
    "fedmax_weights = fed_max(local_weights)\n",
    "\n",
    "# Evaluamos el modelo resultante\n",
    "evaluate_model( fedmax_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos con múltiples rondas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada ronda se entrena localmente, se agregan los resultados y se actualiza el modelo global, que luego vuelve a enviarse a los clientes para comenzar una nueva ronda de entrenamiento. Cada ronda mejora el modelo global a partir de nuevos ajustes locales. Con suficientes rondas y buena agregación se puede alcanzar rendimiento cercano a entrenar un único modelo con todos los datos juntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIMMED MEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed Mean descarta una fracción de los valores más altos y más bajos en cada posición de los pesos antes de calcular el promedio. Así evita que valores atípicos (por ruido o errores de entrenamiento) influyan en la agregación. \n",
    "https://www.investopedia.com/terms/t/trimmed_mean.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.99      0.98      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.98      0.99       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.98      0.99       958\n",
      "           7       0.98      0.97      0.98      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.98      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fed_trimmed_mean(weights, trim_ratio=0.2):\n",
    "    trimmed_weights = []\n",
    "\n",
    "    # itera capa por capa\n",
    "    for layer in zip(*weights):\n",
    "        stacked = np.stack(layer)  #  convierte a array \n",
    "\n",
    "        # calcula cuántos extremos quitar\n",
    "        k = int(trim_ratio * len(stacked))\n",
    "\n",
    "        # ordena por posición\n",
    "        sorted_w = np.sort(stacked, axis=0)\n",
    "\n",
    "        # quita los valores más bajos y más altos\n",
    "        trimmed = sorted_w[k:-k] if k > 0 else stacked\n",
    "\n",
    "        # promedia los valores que quedan\n",
    "        trimmed_weights.append(np.mean(trimmed, axis=0))\n",
    "\n",
    "    return trimmed_weights\n",
    "\n",
    "def federated_rounds_trimmed(local_weights, base_model, rounds=3, trim_ratio=0.2):\n",
    "    # inicializa modelo global con arquitectura base\n",
    "    global_model = tf.keras.models.clone_model(base_model)\n",
    "    global_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # pesos con agregación trimmed mean\n",
    "    global_model.set_weights(fed_trimmed_mean(local_weights, trim_ratio))\n",
    "\n",
    "    for _ in range(rounds):\n",
    "        updated_weights = []\n",
    "\n",
    "        # entrenamiento local de cada cliente\n",
    "        for weights in local_weights:\n",
    "            local_model = tf.keras.models.clone_model(base_model)\n",
    "            local_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # usa los pesos globales actuales como base\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "\n",
    "            # entrena con subconjunto simulado de datos\n",
    "            local_model.fit(x_train[:12000], y_train[:12000], epochs=1, batch_size=32, verbose=0)\n",
    "\n",
    "            # guarda pesos entrenados\n",
    "            updated_weights.append(local_model.get_weights())\n",
    "\n",
    "        # agrega pesos usando otra vez con trimmed mean\n",
    "        global_model.set_weights(fed_trimmed_mean(updated_weights, trim_ratio))\n",
    "\n",
    "    return global_model.get_weights()\n",
    "\n",
    "trimmed_weights = federated_rounds_trimmed(local_weights, base_model)\n",
    "evaluate_model(trimmed_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  FED WEIGHTED AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.97      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.98      0.99      0.99       958\n",
      "           7       0.97      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.98       974\n",
      "           9       0.97      0.98      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def federated_rounds_weighted(local_weights, base_model, local_sizes, rounds=3):\n",
    "    global_model = tf.keras.models.clone_model(base_model)\n",
    "    global_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    global_model.set_weights(fed_weighted_avg(local_weights, local_sizes))\n",
    "\n",
    "    for _ in range(rounds):\n",
    "        updated_weights = []\n",
    "        for weights in local_weights:\n",
    "            local_model = tf.keras.models.clone_model(base_model)\n",
    "            local_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            local_model.fit(x_train[:12000], y_train[:12000], epochs=1, batch_size=32, verbose=0)\n",
    "            updated_weights.append(local_model.get_weights())\n",
    "\n",
    "        global_model.set_weights(fed_weighted_avg(updated_weights, local_sizes))\n",
    "\n",
    "    return global_model.get_weights()\n",
    "\n",
    "fedweighted_multi_weights = federated_rounds_weighted(local_weights, base_model, local_sizes)\n",
    "evaluate_model(fedweighted_multi_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEDAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.98      1.00      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.99      0.98      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.97      0.98       892\n",
      "           6       0.99      0.98      0.99       958\n",
      "           7       0.97      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.97       974\n",
      "           9       0.99      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def federated_rounds_fedavg(local_weights, base_model, rounds=3):\n",
    "    global_model = tf.keras.models.clone_model(base_model)\n",
    "    global_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    global_model.set_weights(fed_avg(local_weights))  # inicializa con FedAvg\n",
    "\n",
    "    for _ in range(rounds):\n",
    "        updated_weights = []\n",
    "        for weights in local_weights:\n",
    "\n",
    "            local_model = tf.keras.models.clone_model(base_model)\n",
    "            local_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            local_model.fit(x_train[:12000], y_train[:12000], epochs=1, batch_size=32, verbose=0)\n",
    "            updated_weights.append(local_model.get_weights())\n",
    "\n",
    "        # nueva agregación\n",
    "        global_model.set_weights(fed_avg(updated_weights))\n",
    "\n",
    "    return global_model.get_weights()\n",
    "\n",
    "fedavg_multi_weights = federated_rounds_fedavg(local_weights, base_model)\n",
    "evaluate_model(fedavg_multi_weights, base_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al evaluar los diferentes métodos nos dimos cuenta que FedMedian y FedMax fueron los peores porque son buenos cuando hay datos extrmos ruidosos o asi, pero en nuestros datos de mnist que son limpios y balanceados, creemos que descartaron información útil. FedAvg y FedWeightedAvg funcionaron mejor que los otros dos porque probablemente toman una representación más distribuida y recopilan mejor la información. Pero definitivamente los modelos mejoraron considerablemente al aplicar múltiples rondas de entrenamiento federado, ya que el modelo global se actualiza iterativamente y se mejora con la retroalimentación de los clientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
